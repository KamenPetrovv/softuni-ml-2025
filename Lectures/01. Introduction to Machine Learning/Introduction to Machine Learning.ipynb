{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b95b3b90-2116-440a-9bca-730e0b824ade",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aa8776-8c93-4eb8-a89e-f8133a84668d",
   "metadata": {},
   "source": [
    "Project: Explain a bit about where the data came from before starting to work on it. If it comes from Kaggle, where did they get it from? Anything inyeresting about it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169a9caa-83a8-47ec-9687-0231f624e5c3",
   "metadata": {},
   "source": [
    "**Interesting:** in-sample and out of sample testing\n",
    "\n",
    "In-sample and out-of-sample testing are methods to evaluate a model's predictive performance by using different datasets. In-sample (IS) testing uses historical data that was used to develop and optimize the model, revealing its fit to that data. Out-of-sample (OOS) testing evaluates the model on completely new, unseen data, assessing its ability to generalize to future conditions and avoid overfitting.\n",
    "\n",
    "**Intersting:** You shouldnt do PCA before doing clustering because PCA loses the clusters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "649ec4b5-cd25-4eaa-a540-b3364f0167b0",
   "metadata": {},
   "source": [
    "## The Scientific Method Steps\n",
    "<img src =\"Images\\hypothesis_testing.jpg\" width=\"300\">\n",
    "\n",
    "1. **Ask a Question**\n",
    "     - It is important we start with a question. Not with the data!\n",
    "2. **Research**\n",
    "     - We often miss this step in the project so far. You might not need research, but whomever is reading the project might need that + explanations\n",
    "     - Often the Reasearch part includes refining the questions we asked. Hidden requirements the stakeholder hasn't thought of.\n",
    "3. **Hypothesis**\n",
    "     - Often we start with Data, then Analyzing and then we form a Hypothesis. It is important we don't do this, because it taints our hypothesis. We create a hidden bias. The Hypothesis has to be formed before we have seen any data.\n",
    "     - In other words: We tell it what to expect when we have already seen the result. Instead of modeling the real world it models our understanding of the world.\n",
    "     - Hypothesis are models for the data. The hypothesis is that this model/function describes the data well.\n",
    "4. **Test with Experiment**\n",
    "     - Training models\n",
    "5. **Analyze your Results**\n",
    "     - Model assessment. Scores, metrics, biases. Explainability, interpretability, A/B testing, etc.\n",
    "6. **Assess if hyphotesis is True or False**\n",
    "     - Repeat the whole cycle again if needed\n",
    "8. **Report results**\n",
    "     - Wheather the hypothesis is True or Fasle we have to report our findings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9e04f1-3551-44ce-876d-1f17fc46adde",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "Standard algorithms are fixed. They dont change. They dont get better with more or less data. They dont perform better in a week or a month. They are a fixed recipe\n",
    "\n",
    "Machine learning allows us to do things the standard alogs don't. \n",
    "Machine learning is allowing computers to learn from data. Tehy do things they weren't explicitly told to do.\n",
    "\n",
    "<img src=\"Images\\ml_process.png\" width=\"900\">\n",
    "\n",
    "**Definitions**:\n",
    "- Parameters - the values the model trains on. It tweaks them so that it minimizes the loss function. Example: The weights of a neural network, the entropy metric it calculates when deciding how to split the decision tree, etc.\n",
    "- Hyperparameters - the settings of the model, before the training begins. They are a constant. If we change them, then we get a different model. Example: Learning rate, tree depth, leaf sample size, SVM kernal, etc.\n",
    "- Loss function - difference between predicted and truth. Allows us to measure and improve the model's performance. We usually use Gradient Descent to minimize that error and get as close as possible to the truth when we predict, so we can rely on the model when we move to predicting cases we don't know the asnwer to.\n",
    "<img src=\"Images\\loss_function.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d77815-287c-442f-8165-08969484c077",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
